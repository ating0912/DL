{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtfPGci82TDd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "lr = 5e-4\n",
        "T = 300\n",
        "img_size = 28\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 固定隨機種子\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "XoSccsGg291B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "9UDLN6o527d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = torch.linspace(1e-4, 0.02, T).to(device)\n",
        "alpha = 1.0 - beta\n",
        "alpha_bar = torch.cumprod(alpha, dim=0)"
      ],
      "metadata": {
        "id": "BowAAjUr25HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, base=64, time_emb_dim=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.time_emb = nn.Sequential(\n",
        "            nn.Linear(1, time_emb_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim)\n",
        "        )\n",
        "        self.label_emb = nn.Embedding(num_classes, time_emb_dim)\n",
        "\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels + time_emb_dim + time_emb_dim, base, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base, base, 3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(base, base * 2, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base * 2, base * 2, 3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(base * 2, base * 4, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(base * 4, base * 4, 3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(base * 4, base * 2, 4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(base * 2, base, 4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv2d(base, in_channels, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t, y):\n",
        "        if t.dim() == 1:\n",
        "            t = t.unsqueeze(-1)\n",
        "        t = self.time_emb(t).view(t.shape[0], -1, 1, 1)\n",
        "        t = t.expand(-1, -1, x.shape[2], x.shape[3])\n",
        "\n",
        "        y = self.label_emb(y).view(y.shape[0], -1, 1, 1)\n",
        "        y = y.expand(-1, -1, x.shape[2], x.shape[3])\n",
        "\n",
        "        x = torch.cat([x, t, y], dim=1)\n",
        "\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "\n",
        "        d1 = self.dec1(e3)\n",
        "        d2 = self.dec2(d1 + e2)\n",
        "        d3 = self.dec3(d2 + e1)\n",
        "\n",
        "        return d3"
      ],
      "metadata": {
        "id": "Td7q3ZoN21z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConditionalUNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "8KsMWglb2zod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q_sample(x0, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x0)\n",
        "    sqrt_alpha_bar = alpha_bar[t].sqrt().view(-1, 1, 1, 1)\n",
        "    sqrt_one_minus_alpha_bar = (1 - alpha_bar[t]).sqrt().view(-1, 1, 1, 1)\n",
        "    return sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise"
      ],
      "metadata": {
        "id": "X5b6gky22uy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "train_start = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        t = torch.randint(0, T, (x.size(0),), device=device)\n",
        "        noise = torch.randn_like(x)\n",
        "        x_t = q_sample(x, t, noise)\n",
        "\n",
        "        noise_pred = model(x_t, t.float() / T, y)\n",
        "        loss = loss_fn(noise_pred, noise)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"📉 Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "print(f\"訓練完成總用時：{time.time() - train_start:.2f} 秒\\n\")\n",
        "# 訓練完成後儲存模型\n",
        "model_path = \"conditional_unet_mnist.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"模型已儲存至 {model_path}\")"
      ],
      "metadata": {
        "id": "kU14A1XU2rxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def p_sample(x_t, t, y):\n",
        "    if isinstance(t, int):\n",
        "        t = torch.full((x_t.size(0),), t, device=device, dtype=torch.long)\n",
        "\n",
        "    beta_t = beta[t].view(-1, 1, 1, 1)\n",
        "    alpha_t = alpha[t].view(-1, 1, 1, 1)\n",
        "    alpha_bar_t = alpha_bar[t].view(-1, 1, 1, 1)\n",
        "\n",
        "    noise_pred = model(x_t, t.float() / T, y)\n",
        "    mean = (1 / alpha_t.sqrt()) * (x_t - ((1 - alpha_t) / (1 - alpha_bar_t).sqrt()) * noise_pred)\n",
        "    noise = torch.randn_like(x_t) if (t[0].item() > 0) else torch.zeros_like(x_t)\n",
        "    return mean + beta_t.sqrt() * noise\n"
      ],
      "metadata": {
        "id": "vASMj7oB2n98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_images(n=10):\n",
        "    model.eval()\n",
        "    x_t = torch.randn(n, 1, img_size, img_size).to(device)\n",
        "    # 隨機生成 0~9 的 label\n",
        "    y = torch.randint(0, 10, (n,), device=device, dtype=torch.long)\n",
        "\n",
        "    start_time = time.time()  # 開始計時\n",
        "    for step in tqdm(reversed(range(T)), desc=\"Sampling random digits\"):\n",
        "        x_t = p_sample(x_t, step, y)\n",
        "\n",
        "    end_time = time.time()    # 結束計時\n",
        "    print(f\"⏱️ 生成 {n} 張圖花費時間: {end_time - start_time:.2f} 秒\")\n",
        "\n",
        "    x_t = (x_t - x_t.min()) / (x_t.max() - x_t.min() + 1e-8)\n",
        "\n",
        "    plt.figure(figsize=(16, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(x_t[i].cpu().view(img_size, img_size), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(\"Generated random digits\", fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "    return x_t\n",
        "\n",
        "sample_images(n=10)\n",
        "# sample_images(target_digit=3, n=10) #指定數字"
      ],
      "metadata": {
        "id": "djWhhrD82d4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推理"
      ],
      "metadata": {
        "id": "s7uWi0oT2ZNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ConditionalUNet().to(device)\n",
        "# model.load_state_dict(torch.load(\"conditional_unet_mnist.pth\", map_location=device))\n",
        "# model.eval()\n",
        "# sample_images(n=10)"
      ],
      "metadata": {
        "id": "74-bilCL2W5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}